<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <meta http-equiv="Content-Security-Policy" content="default-src 'self'; style-src 'self' 'unsafe-inline'; script-src 'self' 'unsafe-inline';" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Soma 3</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 10px; }
    .row { display: flex; gap: 8px; align-items: center; }
    input { flex: 1; padding: 10px; font-size: 14px; }
    button { padding: 10px 12px; font-size: 14px; cursor: pointer; }
    button.recording { background: #ff4444; color: white; animation: pulse 1s infinite; }
    @keyframes pulse {
      0%, 100% { opacity: 1; }
      50% { opacity: 0.6; }
    }
    .status { margin-top: 8px; font-size: 12px; opacity: 0.8; }
    .reply { margin-top: 8px; font-size: 12px; max-height: 48px; overflow: hidden; opacity: 0.9; }
    .voice-indicator { display: none; color: #ff4444; font-weight: bold; margin-top: 4px; font-size: 11px; }
    .voice-indicator.active { display: block; }
  </style>
</head>
<body>
  <div class="row">
    <input id="txt" placeholder="Type or press 🎤 to speak…" autofocus />
    <button id="voice" title="Voice Input (Ctrl+Shift+V)">🎤</button>
    <button id="snap" title="Snapshot">📸</button>
    <button id="send">Send</button>
    <button id="stop" title="Stop speaking">⛔</button>
  </div>

  <div class="voice-indicator" id="voiceIndicator">● Recording... (click 🎤 to stop)</div>
  <div class="status" id="status">Audio-first mode. Ctrl+Shift+V = voice. Ctrl+M = mute. Ctrl+Shift+S = stop.</div>
    <div class="reply" id="reply"></div>

  <div class="status" style="margin-top:10px; font-weight:bold;">Session transcript</div>
  <div id="transcript" style="margin-top:6px; border:1px solid #ddd; padding:8px; height:260px; overflow:auto; white-space:pre-wrap; font-size:12px; background:#fafafa;"></div>

  <script>
    const txt = document.getElementById("txt");
    const send = document.getElementById("send");
    const snap = document.getElementById("snap");
    const voiceBtn = document.getElementById("voice");
    const stopBtn = document.getElementById("stop");
    const status = document.getElementById("status");
    const replyBox = document.getElementById("reply");
    const transcript = document.getElementById("transcript");
    const voiceIndicator = document.getElementById("voiceIndicator");

function nowTime() {
  const d = new Date();
  return d.toLocaleTimeString();
}

function addLogLine(who, msg) {
  if (!transcript) return;
  transcript.textContent += `[${nowTime()}] ${who}: ${msg}\n`;
  transcript.scrollTop = transcript.scrollHeight;
}

    let muted = false;
    let isRecording = false;

    // Voice recording toggle
    async function toggleVoiceRecording() {
      if (isRecording) {
        // Stop recording and transcribe
        voiceBtn.disabled = true;
        status.textContent = "Transcribing...";
        voiceIndicator.classList.remove("active");
        voiceBtn.classList.remove("recording");
        
        const result = await window.soma.stopRecording();
        
        voiceBtn.disabled = false;
        isRecording = false;
        
        if (result.ok && result.text) {
          txt.value = result.text.trim();
          status.textContent = "Voice input ready - press Send";
          txt.focus();
          addLogLine("Voice", result.text.trim());
        } else {
          status.textContent = result.error || "Voice input failed";
        }
      } else {
        // Start recording
        const result = await window.soma.startRecording();
        
        if (result.ok) {
          isRecording = true;
          voiceBtn.classList.add("recording");
          voiceIndicator.classList.add("active");
          status.textContent = "🎤 Listening... (click again or Ctrl+Shift+V to stop)";
        } else {
          status.textContent = result.error || "Failed to start recording";
        }
      }
    }

    // Listen for global hotkey
    window.soma.onVoiceHotkey(() => {
      if (voiceBtn && !voiceBtn.disabled) {
        toggleVoiceRecording();
      }
    });

    async function doSend() {
      const val = txt.value.trim();
      if (!val) return;

      addLogLine("You", val);

      status.textContent = "Sending…";
      replyBox.textContent = "";
      send.disabled = true;
      snap.disabled = true;
      voiceBtn.disabled = true;
      txt.disabled = true;

      const result = await window.soma.send(val);

      send.disabled = false;
      snap.disabled = false;
      voiceBtn.disabled = false;
      txt.disabled = false;
      txt.value = "";
      txt.focus();

      if (result.ok) {
        status.textContent = muted ? "Muted." : "Spoken.";
        replyBox.textContent = result.reply;
        addLogLine("Soma", result.reply);
      } else {
        status.textContent = "Error (see text).";
        replyBox.textContent = result.error || "Unknown error.";
      }
    }

    async function doSnapshot() {
      status.textContent = "Taking snapshot…";
      addLogLine("You", "📸 (snapshot)");
      replyBox.textContent = "";
      send.disabled = true;
      snap.disabled = true;
      voiceBtn.disabled = true;

      const result = await window.soma.snapshot();

      send.disabled = false;
      snap.disabled = false;
      voiceBtn.disabled = false;
      txt.focus();

      if (result.ok) {
        status.textContent = muted ? "Muted." : "Snapshot spoken.";
        replyBox.textContent = result.reply;
        addLogLine("Soma", result.reply);
      } else {
        status.textContent = "Snapshot error (see text).";
        replyBox.textContent = result.error || "Unknown error.";
      }
    }

    stopBtn.addEventListener("click", async () => {
      await window.soma.stop();
      status.textContent = "Speech stopped.";
    });

    send.addEventListener("click", doSend);
    snap.addEventListener("click", doSnapshot);
    voiceBtn.addEventListener("click", toggleVoiceRecording);

    document.addEventListener("keydown", async (e) => {
      if (e.ctrlKey && e.key.toLowerCase() === "m") {
        muted = !muted;
        await window.soma.mute(muted);
        status.textContent = muted ? "Muted." : "Unmuted.";
      }
    });

    txt.addEventListener("keydown", (e) => {
      if (e.key === "Enter") doSend();
      if (e.key === "Escape") {
        if (isRecording) {
          window.soma.cancelRecording();
          isRecording = false;
          voiceBtn.classList.remove("recording");
          voiceIndicator.classList.remove("active");
          status.textContent = "Recording cancelled.";
        } else {
          window.close();
        }
      }
    });

    // Check STT status on load
    window.soma.getSTTStatus().then(sttStatus => {
      if (sttStatus.available) {
        console.log('STT Engine:', sttStatus.engine, '- Quality:', sttStatus.quality);
        if (sttStatus.engine === 'Windows Speech') {
          status.textContent += ' [STT: Fallback mode - install Whisper for better quality]';
        }
      } else {
        voiceBtn.disabled = true;
        voiceBtn.title = "Voice input unavailable";
      }
    });
  </script>
</body>
</html>




